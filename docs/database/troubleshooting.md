# ë°ì´í„°ë² ì´ìŠ¤ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

## ê°œìš”

ë³¸ ë¬¸ì„œëŠ” ê´‘ë‚¨ë™ì„±ë‹¹ ì²­ì†Œë…„ìœ„ì›íšŒ ì˜ˆê²°ì‚° ê´€ë¦¬ ì‹œìŠ¤í…œ ìš´ì˜ ì¤‘ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ë¬¸ì œë“¤ì˜ ì§„ë‹¨ ë° í•´ê²° ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.

**ëŒ€ìƒ ë…ì**:
- ë°±ì—”ë“œ ê°œë°œì
- DevOps ì—”ì§€ë‹ˆì–´
- ì‹œìŠ¤í…œ ê´€ë¦¬ì
- ê¸°ìˆ  ì§€ì›íŒ€

**ì‹œìŠ¤í…œ í™˜ê²½**:
- PostgreSQL 15+
- TypeORM 0.3+
- Node.js + NestJS
- Docker (ì„ íƒì )

**ì‘ì„±ì¼**: 2025ë…„ 1ì›” 11ì¼  
**ìµœì¢… ì—…ë°ì´íŠ¸**: Task 2.16 ì™„ë£Œ ê¸°ì¤€

---

## ëª©ì°¨

1. [ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¬¸ì œ](#1-ë°ì´í„°ë² ì´ìŠ¤-ì—°ê²°-ë¬¸ì œ)
2. [ì„±ëŠ¥ ë¬¸ì œ](#2-ì„±ëŠ¥-ë¬¸ì œ)
3. [ë°ì´í„° ë¬´ê²°ì„± ë¬¸ì œ](#3-ë°ì´í„°-ë¬´ê²°ì„±-ë¬¸ì œ)
4. [TypeORM ê´€ë ¨ ë¬¸ì œ](#4-typeorm-ê´€ë ¨-ë¬¸ì œ)
5. [ë§ˆì´ê·¸ë ˆì´ì…˜ ë¬¸ì œ](#5-ë§ˆì´ê·¸ë ˆì´ì…˜-ë¬¸ì œ)
6. [OCR ë° íŒŒì¼ ì²˜ë¦¬ ë¬¸ì œ](#6-ocr-ë°-íŒŒì¼-ì²˜ë¦¬-ë¬¸ì œ)
7. [ë°±ì—…/ë³µêµ¬ ë¬¸ì œ](#7-ë°±ì—…ë³µêµ¬-ë¬¸ì œ)
8. [ëª¨ë‹ˆí„°ë§ ë° ì§„ë‹¨ ë„êµ¬](#8-ëª¨ë‹ˆí„°ë§-ë°-ì§„ë‹¨-ë„êµ¬)
9. [ì‘ê¸‰ ìƒí™© ëŒ€ì‘](#9-ì‘ê¸‰-ìƒí™©-ëŒ€ì‘)

---

## 1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¬¸ì œ

### 1.1 ì—°ê²° ê±°ë¶€ ì˜¤ë¥˜ (ECONNREFUSED)

#### ì¦ìƒ
```
Error: connect ECONNREFUSED 127.0.0.1:5432
```

#### ì›ì¸ ë¶„ì„
1. PostgreSQL ì„œë¹„ìŠ¤ê°€ ì¤‘ë‹¨ë¨
2. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ
3. ë°©í™”ë²½ ì°¨ë‹¨
4. ì˜ëª»ëœ í˜¸ìŠ¤íŠ¸/í¬íŠ¸ ì„¤ì •

#### í•´ê²° ë°©ë²•

**Step 1: ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸**
```bash
# PostgreSQL ì„œë¹„ìŠ¤ ìƒíƒœ
sudo systemctl status postgresql

# í¬íŠ¸ ë¦¬ìŠ¤ë‹ í™•ì¸
sudo netstat -tlnp | grep 5432

# í”„ë¡œì„¸ìŠ¤ í™•ì¸
ps aux | grep postgres
```

**Step 2: ì„œë¹„ìŠ¤ ì¬ì‹œì‘**
```bash
# ì„œë¹„ìŠ¤ ì¬ì‹œì‘
sudo systemctl restart postgresql

# ì„œë¹„ìŠ¤ í™œì„±í™” (ë¶€íŒ… ì‹œ ìë™ ì‹œì‘)
sudo systemctl enable postgresql

# ë¡œê·¸ í™•ì¸
sudo journalctl -u postgresql -n 50
```

**Step 3: ë°©í™”ë²½ ì„¤ì •**
```bash
# ë°©í™”ë²½ ìƒíƒœ í™•ì¸
sudo ufw status

# PostgreSQL í¬íŠ¸ í—ˆìš©
sudo ufw allow 5432/tcp

# íŠ¹ì • IPë§Œ í—ˆìš© (ë³´ì•ˆ ê°•í™”)
sudo ufw allow from 192.168.1.0/24 to any port 5432
```

### 1.2 ì¸ì¦ ì‹¤íŒ¨ (authentication failed)

#### ì¦ìƒ
```
FATAL: password authentication failed for user "recipt_user"
```

#### í•´ê²° ë°©ë²•

**Step 1: ì‚¬ìš©ì ì¡´ì¬ ì—¬ë¶€ í™•ì¸**
```sql
-- PostgreSQLì— ìŠˆí¼ìœ ì €ë¡œ ì—°ê²°
sudo -u postgres psql

-- ì‚¬ìš©ì ëª©ë¡ í™•ì¸
\du

-- ì‚¬ìš©ìê°€ ì—†ë‹¤ë©´ ìƒì„±
CREATE USER recipt_user WITH PASSWORD 'secure_password_2025';
```

**Step 2: ê¶Œí•œ ë¶€ì—¬**
```sql
-- ë°ì´í„°ë² ì´ìŠ¤ ì ‘ê·¼ ê¶Œí•œ
GRANT CONNECT ON DATABASE recipt_production TO recipt_user;

-- ìŠ¤í‚¤ë§ˆ ì‚¬ìš© ê¶Œí•œ
GRANT USAGE ON SCHEMA public TO recipt_user;

-- í…Œì´ë¸” ê¶Œí•œ
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO recipt_user;

-- ì‹œí€€ìŠ¤ ê¶Œí•œ
GRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO recipt_user;

-- í–¥í›„ ìƒì„±ë  ê°ì²´ì— ëŒ€í•œ ê¸°ë³¸ ê¶Œí•œ
ALTER DEFAULT PRIVILEGES IN SCHEMA public 
GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO recipt_user;
```

**Step 3: pg_hba.conf ì„¤ì • í™•ì¸**
```bash
# ì„¤ì • íŒŒì¼ ìœ„ì¹˜ í™•ì¸
sudo -u postgres psql -c "SHOW hba_file;"

# ì„¤ì • íŒŒì¼ í¸ì§‘
sudo nano /etc/postgresql/15/main/pg_hba.conf

# ë‹¤ìŒ ë¼ì¸ ì¶”ê°€ ë˜ëŠ” ìˆ˜ì •
local   recipt_production   recipt_user                     md5
host    recipt_production   recipt_user   127.0.0.1/32      md5
host    recipt_production   recipt_user   ::1/128           md5

# ì„¤ì • ì ìš©
sudo systemctl reload postgresql
```

### 1.3 ì—°ê²° í’€ ê³ ê°ˆ (connection pool exhausted)

#### ì¦ìƒ
```
Error: Connection pool exhausted. Maximum connections: 10
```

#### í•´ê²° ë°©ë²•

**Step 1: í˜„ì¬ ì—°ê²° ìƒíƒœ í™•ì¸**
```sql
-- í˜„ì¬ ì—°ê²° ìˆ˜ í™•ì¸
SELECT count(*) as active_connections 
FROM pg_stat_activity 
WHERE state = 'active';

-- ìœ íœ´ ì—°ê²° í™•ì¸
SELECT count(*) as idle_connections 
FROM pg_stat_activity 
WHERE state = 'idle';

-- ì˜¤ë˜ëœ ì—°ê²° í™•ì¸
SELECT pid, usename, application_name, client_addr, state,
       now() - state_change as idle_duration
FROM pg_stat_activity 
WHERE state = 'idle'
ORDER BY state_change;
```

**Step 2: TypeORM ì—°ê²° í’€ ì„¤ì • ìµœì í™”**
```typescript
// data-source.ts
export const AppDataSource = new DataSource({
    // ... ê¸°íƒ€ ì„¤ì •
    
    // ì—°ê²° í’€ ì„¤ì •
    extra: {
        max: 20,                    // ìµœëŒ€ ì—°ê²° ìˆ˜
        min: 5,                     // ìµœì†Œ ì—°ê²° ìˆ˜
        acquireTimeoutMillis: 30000, // ì—°ê²° íšë“ íƒ€ì„ì•„ì›ƒ
        idleTimeoutMillis: 600000,   // ìœ íœ´ ì—°ê²° íƒ€ì„ì•„ì›ƒ (10ë¶„)
        reapIntervalMillis: 1000,    // ì—°ê²° ì •ë¦¬ ê°„ê²©
        createRetryIntervalMillis: 200, // ì¬ì‹œë„ ê°„ê²©
        
        // ì—°ê²° ìƒì„± íƒ€ì„ì•„ì›ƒ
        createTimeoutMillis: 30000,
    }
});
```

**Step 3: PostgreSQL ì„¤ì • ì¡°ì •**
```sql
-- ìµœëŒ€ ì—°ê²° ìˆ˜ ì¦ê°€ (ì¬ì‹œì‘ í•„ìš”)
ALTER SYSTEM SET max_connections = 200;

-- ì„¤ì • ì ìš©
SELECT pg_reload_conf();

-- ë˜ëŠ” postgresql.conf ì§ì ‘ ìˆ˜ì •
-- max_connections = 200
```

---

## 2. ì„±ëŠ¥ ë¬¸ì œ

### 2.1 ëŠë¦° ì¿¼ë¦¬ ì§„ë‹¨

#### ì¦ìƒ
- API ì‘ë‹µ ì‹œê°„ì´ 5ì´ˆ ì´ìƒ
- ë°ì´í„°ë² ì´ìŠ¤ CPU ì‚¬ìš©ë¥  90% ì´ˆê³¼
- ë™ì‹œ ì ‘ì†ì ì¦ê°€ ì‹œ ì„±ëŠ¥ ê¸‰ê²©íˆ ì €í•˜

#### ì§„ë‹¨ ë°©ë²•

**Step 1: í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì¿¼ë¦¬ í™•ì¸**
```sql
-- ì˜¤ë˜ ì‹¤í–‰ë˜ëŠ” ì¿¼ë¦¬ ì°¾ê¸°
SELECT 
    pid,
    now() - pg_stat_activity.query_start AS duration,
    query,
    state
FROM pg_stat_activity
WHERE (now() - pg_stat_activity.query_start) > interval '5 seconds'
    AND state = 'active'
ORDER BY duration DESC;

-- ë½ ëŒ€ê¸° ì¤‘ì¸ ì¿¼ë¦¬
SELECT 
    blocked_locks.pid AS blocked_pid,
    blocked_activity.usename AS blocked_user,
    blocking_locks.pid AS blocking_pid,
    blocking_activity.usename AS blocking_user,
    blocked_activity.query AS blocked_statement,
    blocking_activity.query AS current_statement_in_blocking_process
FROM pg_catalog.pg_locks blocked_locks
JOIN pg_catalog.pg_stat_activity blocked_activity ON blocked_activity.pid = blocked_locks.pid
JOIN pg_catalog.pg_locks blocking_locks ON blocking_locks.locktype = blocked_locks.locktype
    AND blocking_locks.database IS NOT DISTINCT FROM blocked_locks.database
    AND blocking_locks.relation IS NOT DISTINCT FROM blocked_locks.relation
    AND blocking_locks.page IS NOT DISTINCT FROM blocked_locks.page
    AND blocking_locks.tuple IS NOT DISTINCT FROM blocked_locks.tuple
    AND blocking_locks.virtualxid IS NOT DISTINCT FROM blocked_locks.virtualxid
    AND blocking_locks.transactionid IS NOT DISTINCT FROM blocked_locks.transactionid
    AND blocking_locks.classid IS NOT DISTINCT FROM blocked_locks.classid
    AND blocking_locks.objid IS NOT DISTINCT FROM blocked_locks.objid
    AND blocking_locks.objsubid IS NOT DISTINCT FROM blocked_locks.objsubid
    AND blocking_locks.pid != blocked_locks.pid
JOIN pg_catalog.pg_stat_activity blocking_activity ON blocking_activity.pid = blocking_locks.pid
WHERE NOT blocked_locks.granted;
```

**Step 2: ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„**
```sql
-- ì‹¤í–‰ ê³„íš í™•ì¸
EXPLAIN ANALYZE
SELECT u.name, uo.role, o.name as org_name
FROM users u
JOIN user_organizations uo ON u.id = uo.user_id
JOIN organizations o ON uo.organization_id = o.id
WHERE u.status = 'ACTIVE'
ORDER BY u.created_at DESC
LIMIT 100;

-- ë²„í¼ ì‚¬ìš©ëŸ‰ê¹Œì§€ í¬í•¨
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM budgets WHERE status = 'APPROVED';
```

**Step 3: ì¸ë±ìŠ¤ ì‚¬ìš©ë¥  í™•ì¸**
```sql
-- ì¸ë±ìŠ¤ ì‚¬ìš© í†µê³„
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_tup_read,
    idx_tup_fetch,
    idx_tup_read / NULLIF(idx_tup_fetch, 0) as ratio
FROM pg_stat_user_indexes
ORDER BY idx_tup_read DESC;

-- ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì¸ë±ìŠ¤
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    pg_size_pretty(pg_relation_size(indexrelid)) as size
FROM pg_stat_user_indexes
WHERE idx_scan = 0
    AND schemaname = 'public'
ORDER BY pg_relation_size(indexrelid) DESC;
```

#### í•´ê²° ë°©ë²•

**ì¸ë±ìŠ¤ ìµœì í™”**
```sql
-- ë³µí•© ì¸ë±ìŠ¤ ìƒì„± (ìì£¼ í•¨ê»˜ ì¡°íšŒë˜ëŠ” ì»¬ëŸ¼)
CREATE INDEX CONCURRENTLY idx_user_organizations_active 
ON user_organizations(user_id, status) 
WHERE status = 'ACTIVE';

-- ë¶€ë¶„ ì¸ë±ìŠ¤ (íŠ¹ì • ì¡°ê±´ì˜ ë°ì´í„°ë§Œ)
CREATE INDEX CONCURRENTLY idx_budgets_approved 
ON budgets(created_at DESC) 
WHERE status = 'APPROVED';

-- ì „ë¬¸ ê²€ìƒ‰ ì¸ë±ìŠ¤
CREATE INDEX CONCURRENTLY idx_events_name_search 
ON events USING gin(name gin_trgm_ops);
```

**ì¿¼ë¦¬ ìµœì í™”**
```sql
-- N+1 ë¬¸ì œ í•´ê²° (TypeORM)
-- Before: ê° ì˜ˆì‚°ë§ˆë‹¤ ê°œë³„ ì¿¼ë¦¬
const budgets = await budgetRepository.find();
for (const budget of budgets) {
    budget.organization = await organizationRepository.findOne(budget.organizationId);
}

-- After: JOINì„ ì‚¬ìš©í•œ ë‹¨ì¼ ì¿¼ë¦¬
const budgets = await budgetRepository.find({
    relations: ['organization']
});
```

### 2.2 ë©”ëª¨ë¦¬ ë¬¸ì œ

#### ì¦ìƒ
```
FATAL: out of memory
DETAIL: Failed on request of size 134217728.
```

#### í•´ê²° ë°©ë²•

**Step 1: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸**
```sql
-- í˜„ì¬ ë©”ëª¨ë¦¬ ì„¤ì • í™•ì¸
SELECT name, setting, unit, context 
FROM pg_settings 
WHERE name IN ('shared_buffers', 'work_mem', 'maintenance_work_mem', 'effective_cache_size');

-- ë©”ëª¨ë¦¬ ì‚¬ìš© í†µê³„
SELECT 
    datname,
    temp_files,
    temp_bytes,
    pg_size_pretty(temp_bytes) as temp_size
FROM pg_stat_database
WHERE temp_files > 0;
```

**Step 2: PostgreSQL ë©”ëª¨ë¦¬ ì„¤ì • ìµœì í™”**
```bash
# postgresql.conf í¸ì§‘
sudo nano /etc/postgresql/15/main/postgresql.conf

# ë©”ëª¨ë¦¬ ì„¤ì • (ì‹œìŠ¤í…œ RAMì˜ ì•½ 25%)
shared_buffers = 256MB
work_mem = 4MB
maintenance_work_mem = 64MB
effective_cache_size = 1GB

# ì„¤ì • ì ìš©
sudo systemctl restart postgresql
```

### 2.3 ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±

#### ì¦ìƒ
```
ERROR: could not extend file "base/16384/16389": No space left on device
```

#### í•´ê²° ë°©ë²•

**Step 1: ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸**
```bash
# ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
df -h

# PostgreSQL ë°ì´í„° ë””ë ‰í† ë¦¬ í¬ê¸°
sudo du -sh /var/lib/postgresql/15/main/

# ë°ì´í„°ë² ì´ìŠ¤ë³„ í¬ê¸°
sudo -u postgres psql -c "
SELECT 
    datname,
    pg_size_pretty(pg_database_size(datname)) as size
FROM pg_database
ORDER BY pg_database_size(datname) DESC;
"
```

**Step 2: ë¶ˆí•„ìš”í•œ ë°ì´í„° ì •ë¦¬**
```sql
-- ì˜¤ë˜ëœ ê°ì‚¬ ë¡œê·¸ ì‚­ì œ (6ê°œì›” ì´ì „)
DELETE FROM audit_trails 
WHERE created_at < NOW() - INTERVAL '6 months';

-- VACUUMìœ¼ë¡œ ë””ìŠ¤í¬ ê³µê°„ íšŒìˆ˜
VACUUM FULL audit_trails;

-- ìë™ VACUUM ì„¤ì • í™•ì¸
SELECT name, setting FROM pg_settings WHERE name LIKE '%vacuum%';
```

**Step 3: ë¡œê·¸ íŒŒì¼ ì •ë¦¬**
```bash
# PostgreSQL ë¡œê·¸ íŒŒì¼ ì •ë¦¬
sudo find /var/log/postgresql -name "*.log" -mtime +30 -delete

# ë¡œê·¸ ë¡œí…Œì´ì…˜ ì„¤ì • í™•ì¸
sudo nano /etc/logrotate.d/postgresql-common
```

---

## 3. ë°ì´í„° ë¬´ê²°ì„± ë¬¸ì œ

### 3.1 ì™¸ë˜í‚¤ ì œì•½ì¡°ê±´ ìœ„ë°˜

#### ì¦ìƒ
```
ERROR: insert or update on table "user_organizations" violates foreign key constraint "FK_user_organizations_user_id"
DETAIL: Key (user_id)=(550e8400-e29b-41d4-a716-446655440000) is not present in table "users".
```

#### í•´ê²° ë°©ë²•

**Step 1: ê³ ì•„ ë ˆì½”ë“œ í™•ì¸**
```sql
-- ê³ ì•„ ë ˆì½”ë“œ ì°¾ê¸°
SELECT uo.id, uo.user_id
FROM user_organizations uo
LEFT JOIN users u ON uo.user_id = u.id
WHERE u.id IS NULL;

-- ì°¸ì¡°ë˜ì§€ ì•ŠëŠ” ì¡°ì§ ì°¾ê¸°
SELECT o.id, o.name
FROM organizations o
LEFT JOIN user_organizations uo ON o.id = uo.organization_id
WHERE uo.organization_id IS NULL;
```

**Step 2: ë°ì´í„° ì •ë¦¬**
```sql
-- ê³ ì•„ ë ˆì½”ë“œ ì‚­ì œ (ì£¼ì˜: ë°±ì—… í›„ ì‹¤í–‰)
DELETE FROM user_organizations 
WHERE user_id NOT IN (SELECT id FROM users);

-- ë˜ëŠ” ì•ˆì „í•˜ê²Œ ë¹„í™œì„±í™”
UPDATE user_organizations 
SET is_active = false 
WHERE user_id NOT IN (SELECT id FROM users);
```

**Step 3: ì œì•½ì¡°ê±´ ì¬ìƒì„±**
```sql
-- ê¸°ì¡´ ì œì•½ì¡°ê±´ ì‚­ì œ
ALTER TABLE user_organizations 
DROP CONSTRAINT IF EXISTS FK_user_organizations_user_id;

-- ìƒˆ ì œì•½ì¡°ê±´ ì¶”ê°€
ALTER TABLE user_organizations 
ADD CONSTRAINT FK_user_organizations_user_id 
FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE;
```

### 3.2 ì¤‘ë³µ ë°ì´í„° ë¬¸ì œ

#### ì¦ìƒ
```
ERROR: duplicate key value violates unique constraint "users_email_key"
DETAIL: Key (email)=(test@example.com) already exists.
```

#### í•´ê²° ë°©ë²•

**Step 1: ì¤‘ë³µ ë°ì´í„° í™•ì¸**
```sql
-- ì¤‘ë³µ ì´ë©”ì¼ ì°¾ê¸°
SELECT email, COUNT(*) as count
FROM users
GROUP BY email
HAVING COUNT(*) > 1;

-- ì¤‘ë³µ ë ˆì½”ë“œ ìƒì„¸ í™•ì¸
SELECT id, email, name, created_at
FROM users
WHERE email IN (
    SELECT email FROM users GROUP BY email HAVING COUNT(*) > 1
)
ORDER BY email, created_at;
```

**Step 2: ì¤‘ë³µ ë°ì´í„° ì •ë¦¬**
```sql
-- ê°€ì¥ ì˜¤ë˜ëœ ë ˆì½”ë“œë§Œ ë‚¨ê¸°ê³  ì‚­ì œ
DELETE FROM users u1
USING users u2
WHERE u1.id > u2.id 
    AND u1.email = u2.email;

-- ë˜ëŠ” ìµœì‹  ë ˆì½”ë“œë§Œ ë‚¨ê¸°ê³  ì‚­ì œ
DELETE FROM users
WHERE id NOT IN (
    SELECT DISTINCT ON (email) id
    FROM users
    ORDER BY email, created_at DESC
);
```

### 3.3 ì²´í¬ ì œì•½ì¡°ê±´ ìœ„ë°˜

#### ì¦ìƒ
```
ERROR: new row for relation "users" violates check constraint "users_email_check"
DETAIL: Failing row contains (..., invalid-email, ...).
```

#### í•´ê²° ë°©ë²•

**Step 1: ì˜ëª»ëœ ë°ì´í„° í™•ì¸**
```sql
-- ì´ë©”ì¼ í˜•ì‹ì´ ì˜ëª»ëœ ì‚¬ìš©ì
SELECT id, email
FROM users
WHERE email !~ '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$';

-- ì „í™”ë²ˆí˜¸ í˜•ì‹ í™•ì¸
SELECT id, phone
FROM users
WHERE phone IS NOT NULL 
    AND phone !~ '^[0-9-]{10,15}$';

-- ë‚ ì§œ ìœ íš¨ì„± í™•ì¸
SELECT id, start_date, end_date
FROM events
WHERE start_date > end_date;
```

**Step 2: ë°ì´í„° ì •ì •**
```sql
-- ì´ë©”ì¼ ì£¼ì†Œ ì •ì • (ì„ì‹œ ë°©ë²•)
UPDATE users 
SET email = CONCAT('temp_', id, '@example.com')
WHERE email !~ '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$';

-- ì „í™”ë²ˆí˜¸ ì •ì •
UPDATE users 
SET phone = REGEXP_REPLACE(phone, '[^0-9-]', '', 'g')
WHERE phone IS NOT NULL;
```

---

## 4. TypeORM ê´€ë ¨ ë¬¸ì œ

### 4.1 Entity ë™ê¸°í™” ë¬¸ì œ

#### ì¦ìƒ
```
EntityMetadataNotFoundError: No metadata for "User" was found.
```

#### í•´ê²° ë°©ë²•

**Step 1: Entity ë“±ë¡ í™•ì¸**
```typescript
// data-source.ts
export const AppDataSource = new DataSource({
    // Entity ê²½ë¡œ í™•ì¸
    entities: [
        __dirname + '/../**/*.entity{.ts,.js}',
        // ë˜ëŠ” ëª…ì‹œì  ë“±ë¡
        User,
        Organization,
        UserOrganization,
        // ... ë‹¤ë¥¸ Entityë“¤
    ],
});
```

**Step 2: ì„í¬íŠ¸ ê²½ë¡œ í™•ì¸**
```typescript
// ì˜ëª»ëœ ì˜ˆ
import { User } from './user.entity'; // ìƒëŒ€ ê²½ë¡œ ë¬¸ì œ

// ì˜¬ë°”ë¥¸ ì˜ˆ
import { User } from '@/entities/user.entity';
```

### 4.2 íŠ¸ëœì­ì…˜ ë¬¸ì œ

#### ì¦ìƒ
```
QueryFailedError: current transaction is aborted, commands ignored until end of transaction block
```

#### í•´ê²° ë°©ë²•

**Step 1: íŠ¸ëœì­ì…˜ ìƒíƒœ í™•ì¸**
```typescript
// íŠ¸ëœì­ì…˜ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
async function safeTransaction() {
    const queryRunner = AppDataSource.createQueryRunner();
    
    await queryRunner.connect();
    await queryRunner.startTransaction();
    
    try {
        // íŠ¸ëœì­ì…˜ ì‘ì—…
        await queryRunner.manager.save(user);
        await queryRunner.manager.save(userOrganization);
        
        await queryRunner.commitTransaction();
    } catch (error) {
        // ë¡¤ë°±
        await queryRunner.rollbackTransaction();
        console.error('Transaction failed:', error);
        throw error;
    } finally {
        // ì—°ê²° í•´ì œ
        await queryRunner.release();
    }
}
```

**Step 2: ë°ë“œë½ ì²˜ë¦¬**
```typescript
// ì¬ì‹œë„ ë¡œì§ í¬í•¨
async function executeWithRetry<T>(
    operation: () => Promise<T>,
    maxRetries = 3
): Promise<T> {
    for (let i = 0; i < maxRetries; i++) {
        try {
            return await operation();
        } catch (error) {
            if (error.code === '40P01' && i < maxRetries - 1) {
                // ë°ë“œë½ ë°œìƒ ì‹œ ì¬ì‹œë„
                console.warn(`Deadlock detected, retrying... (${i + 1}/${maxRetries})`);
                await new Promise(resolve => setTimeout(resolve, 100 * Math.pow(2, i)));
                continue;
            }
            throw error;
        }
    }
}
```

### 4.3 ì»¤ë„¥ì…˜ ë¦¬í¬ ë¬¸ì œ

#### ì¦ìƒ
- ì—°ê²° í’€ì´ ê³„ì† ì¦ê°€
- "too many clients" ì˜¤ë¥˜
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì§€ì† ì¦ê°€

#### í•´ê²° ë°©ë²•

**Step 1: ì—°ê²° ì¶”ì **
```typescript
// ì»¤ë„¥ì…˜ ë¦¬í¬ ë””ë²„ê¹…
class ConnectionTracker {
    private static connections = new Map<string, Date>();
    
    static track(id: string) {
        this.connections.set(id, new Date());
        console.log(`Connection created: ${id} (Total: ${this.connections.size})`);
    }
    
    static untrack(id: string) {
        this.connections.delete(id);
        console.log(`Connection released: ${id} (Total: ${this.connections.size})`);
    }
    
    static getActiveConnections() {
        return Array.from(this.connections.entries());
    }
}
```

**Step 2: Repository íŒ¨í„´ ì˜¬ë°”ë¥¸ ì‚¬ìš©**
```typescript
// ì˜ëª»ëœ ì˜ˆ - ìƒˆ ì—°ê²° ìƒì„±
const repository = new Repository(User, manager); // âŒ

// ì˜¬ë°”ë¥¸ ì˜ˆ - ê¸°ì¡´ ì—°ê²° ì¬ì‚¬ìš©
const repository = AppDataSource.getRepository(User); // âœ…

// ë˜ëŠ” ì˜ì¡´ì„± ì£¼ì… ì‚¬ìš©
@Injectable()
export class UserService {
    constructor(
        @InjectRepository(User)
        private userRepository: Repository<User>
    ) {}
}
```

---

## 5. ë§ˆì´ê·¸ë ˆì´ì…˜ ë¬¸ì œ

### 5.1 ë§ˆì´ê·¸ë ˆì´ì…˜ ë¡¤ë°± ì‹¤íŒ¨

#### ì¦ìƒ
```
Error during revert migration: column "old_column" does not exist
```

#### í•´ê²° ë°©ë²•

**Step 1: ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒíƒœ í™•ì¸**
```sql
-- ë§ˆì´ê·¸ë ˆì´ì…˜ í…Œì´ë¸” í™•ì¸
SELECT * FROM typeorm_migrations ORDER BY timestamp DESC;

-- ìˆ˜ë™ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ ê¸°ë¡ ì‚­ì œ (ì£¼ì˜!)
DELETE FROM typeorm_migrations 
WHERE name = 'FailedMigration1757400000000';
```

**Step 2: ìŠ¤í‚¤ë§ˆ ìˆ˜ë™ ë³µêµ¬**
```sql
-- í…Œì´ë¸” êµ¬ì¡° í™•ì¸
\d+ users

-- ì»¬ëŸ¼ì´ ì´ë¯¸ ì‚­ì œë˜ì—ˆë‹¤ë©´ ë‹¤ì‹œ ìƒì„±
ALTER TABLE users ADD COLUMN old_column VARCHAR(255);

-- ê·¸ í›„ ì •ìƒì ì¸ ë¡¤ë°± ì‹¤í–‰
npm run migration:revert
```

### 5.2 ë§ˆì´ê·¸ë ˆì´ì…˜ êµì°©ìƒíƒœ

#### ì¦ìƒ
```
Error: Migration is already running
```

#### í•´ê²° ë°©ë²•

**Step 1: ì‹¤í–‰ ì¤‘ì¸ ë§ˆì´ê·¸ë ˆì´ì…˜ í™•ì¸**
```sql
-- ì¥ì‹œê°„ ì‹¤í–‰ë˜ëŠ” ì¿¼ë¦¬ í™•ì¸
SELECT pid, query, state, now() - query_start as duration
FROM pg_stat_activity
WHERE query LIKE '%CREATE%' OR query LIKE '%ALTER%'
ORDER BY query_start;

-- í•„ìš”ì‹œ ê°•ì œ ì¢…ë£Œ (ë§¤ìš° ì£¼ì˜!)
SELECT pg_terminate_backend(pid) 
FROM pg_stat_activity 
WHERE pid = [ë¬¸ì œ_í”„ë¡œì„¸ìŠ¤_PID];
```

**Step 2: ë§ˆì´ê·¸ë ˆì´ì…˜ ë½ í•´ì œ**
```sql
-- TypeORM ë§ˆì´ê·¸ë ˆì´ì…˜ ë½ í™•ì¸
SELECT * FROM pg_locks 
WHERE locktype = 'advisory' 
AND classid = 1573240463;

-- ë½ ê°•ì œ í•´ì œ (ì‘ê¸‰ ìƒí™©ì—ë§Œ)
SELECT pg_advisory_unlock_all();
```

---

## 6. OCR ë° íŒŒì¼ ì²˜ë¦¬ ë¬¸ì œ

### 6.1 OCR ì²˜ë¦¬ ì‹¤íŒ¨

#### ì¦ìƒ
- OCR ì‘ì—…ì´ `PROCESSING` ìƒíƒœì—ì„œ ë©ˆì¶¤
- ì—ëŸ¬ ë©”ì‹œì§€: "Tesseract failed to process image"
- ì˜ìˆ˜ì¦ í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼ê°€ ë¶€ì •í™•

#### ì§„ë‹¨ ë°©ë²•

**Step 1: OCR ì‘ì—… ìƒíƒœ í™•ì¸**
```sql
-- ì˜¤ë˜ëœ ì²˜ë¦¬ ì¤‘ ì‘ì—… í™•ì¸
SELECT id, receipt_scan_id, engine, processing_stage, 
       created_at, updated_at,
       EXTRACT(EPOCH FROM (NOW() - updated_at))/60 as minutes_stuck
FROM ocr_results
WHERE status = 'PROCESSING'
    AND updated_at < NOW() - INTERVAL '30 minutes'
ORDER BY updated_at;

-- ì‹¤íŒ¨ìœ¨ í†µê³„
SELECT 
    engine,
    COUNT(*) as total,
    SUM(CASE WHEN status = 'COMPLETED' THEN 1 ELSE 0 END) as successful,
    SUM(CASE WHEN status = 'FAILED' THEN 1 ELSE 0 END) as failed,
    ROUND(
        100.0 * SUM(CASE WHEN status = 'COMPLETED' THEN 1 ELSE 0 END) / COUNT(*), 
        2
    ) as success_rate
FROM ocr_results
GROUP BY engine;
```

#### í•´ê²° ë°©ë²•

**Step 1: ë©ˆì¶˜ ì‘ì—… ì¬ì²˜ë¦¬**
```sql
-- ë©ˆì¶˜ ì‘ì—…ì„ PENDING ìƒíƒœë¡œ ë˜ëŒë¦¬ê¸°
UPDATE ocr_results 
SET status = 'PENDING', 
    processing_started_at = NULL,
    error_message = 'Reset due to timeout'
WHERE status = 'PROCESSING'
    AND updated_at < NOW() - INTERVAL '30 minutes';
```

**Step 2: OCR ì—”ì§„ ì„¤ì • ìµœì í™”**
```typescript
// OCR ì„œë¹„ìŠ¤ ì„¤ì •
export class OCRService {
    private readonly tesseractConfig = {
        lang: 'kor+eng',
        oem: 1,
        psm: 3,
        timeout: 30000, // 30ì´ˆ íƒ€ì„ì•„ì›ƒ
    };
    
    private readonly easyOCRConfig = {
        gpu: false,
        languages: ['ko', 'en'],
        width_ths: 0.7,
        height_ths: 0.7,
    };
    
    async processWithFallback(imagePath: string): Promise<OCRResult> {
        try {
            // 1ì°¨: Tesseract
            return await this.processTesseract(imagePath);
        } catch (error) {
            console.warn('Tesseract failed, trying EasyOCR:', error);
            
            try {
                // 2ì°¨: EasyOCR
                return await this.processEasyOCR(imagePath);
            } catch (error2) {
                console.error('All OCR engines failed:', error2);
                throw new Error('OCR processing failed');
            }
        }
    }
}
```

### 6.2 íŒŒì¼ ì—…ë¡œë“œ ë¬¸ì œ

#### ì¦ìƒ
```
Error: File upload failed - ENOSPC: no space left on device
```

#### í•´ê²° ë°©ë²•

**Step 1: ë””ìŠ¤í¬ ê³µê°„ í™•ì¸**
```bash
# ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ìš©ëŸ‰ í™•ì¸
df -h /var/www/recipt/uploads/

# í° íŒŒì¼ë“¤ ì°¾ê¸°
find /var/www/recipt/uploads/ -type f -size +10M -exec ls -lh {} \;

# ì˜¤ë˜ëœ ì„ì‹œ íŒŒì¼ ì •ë¦¬
find /var/www/recipt/uploads/temp/ -type f -mtime +7 -delete
```

**Step 2: íŒŒì¼ ì •ë¦¬ ìë™í™”**
```bash
# í¬ë¡ ì¡ ì„¤ì •
crontab -e

# ë§¤ì¼ ìƒˆë²½ 2ì‹œì— ì˜¤ë˜ëœ íŒŒì¼ ì •ë¦¬
0 2 * * * find /var/www/recipt/uploads/temp/ -type f -mtime +7 -delete

# ë§¤ì£¼ ì¼ìš”ì¼ì— ì¸ë„¤ì¼ ì¬ìƒì„±
0 3 * * 0 /home/recipt/scripts/cleanup_thumbnails.sh
```

### 6.3 ì´ë¯¸ì§€ ì²˜ë¦¬ ë©”ëª¨ë¦¬ ë¶€ì¡±

#### ì¦ìƒ
```
Error: Image processing failed - Cannot allocate memory
```

#### í•´ê²° ë°©ë²•

**Step 1: ì´ë¯¸ì§€ í¬ê¸° ì œí•œ**
```typescript
// ì´ë¯¸ì§€ ì—…ë¡œë“œ ë¯¸ë“¤ì›¨ì–´
export const imageUploadConfig = {
    fileSize: 10 * 1024 * 1024, // 10MB ì œí•œ
    fileFilter: (req, file, cb) => {
        if (!file.mimetype.startsWith('image/')) {
            return cb(new Error('Only image files allowed'), false);
        }
        cb(null, true);
    },
};

// ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•
async function resizeImage(inputPath: string, outputPath: string) {
    const image = sharp(inputPath);
    const metadata = await image.metadata();
    
    // í° ì´ë¯¸ì§€ëŠ” ë¦¬ì‚¬ì´ì§•
    if (metadata.width > 2048 || metadata.height > 2048) {
        await image
            .resize(2048, 2048, { fit: 'inside', withoutEnlargement: true })
            .jpeg({ quality: 85 })
            .toFile(outputPath);
    } else {
        // ì‘ì€ ì´ë¯¸ì§€ëŠ” ê·¸ëŒ€ë¡œ ë³µì‚¬
        await fs.copyFile(inputPath, outputPath);
    }
}
```

---

## 7. ë°±ì—…/ë³µêµ¬ ë¬¸ì œ

### 7.1 ë°±ì—… ì‹¤íŒ¨

#### ì¦ìƒ
```
pg_dump: error: connection to database "recipt_production" failed: FATAL: remaining connection slots are reserved
```

#### í•´ê²° ë°©ë²•

**Step 1: ì „ìš© ë°±ì—… ì‚¬ìš©ì ìƒì„±**
```sql
-- ë°±ì—… ì „ìš© ì‚¬ìš©ì ìƒì„±
CREATE USER backup_user WITH PASSWORD 'backup_password_2025';

-- ìµœì†Œ ê¶Œí•œ ë¶€ì—¬
GRANT CONNECT ON DATABASE recipt_production TO backup_user;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO backup_user;

-- í–¥í›„ ìƒì„±ë  í…Œì´ë¸”ì— ëŒ€í•œ ê¶Œí•œ
ALTER DEFAULT PRIVILEGES IN SCHEMA public 
GRANT SELECT ON TABLES TO backup_user;
```

**Step 2: ë°±ì—… ìŠ¤í¬ë¦½íŠ¸ ê°œì„ **
```bash
#!/bin/bash
# backup-database.sh

set -e  # ì˜¤ë¥˜ ì‹œ ìŠ¤í¬ë¦½íŠ¸ ì¤‘ë‹¨

BACKUP_DIR="/backup/database"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="recipt_backup_${TIMESTAMP}.sql"

# ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
AVAILABLE_SPACE=$(df $BACKUP_DIR | tail -1 | awk '{print $4}')
if [ $AVAILABLE_SPACE -lt 1000000 ]; then  # 1GB ë¯¸ë§Œ
    echo "âŒ Insufficient disk space: ${AVAILABLE_SPACE}KB"
    exit 1
fi

# ë°±ì—… ì‹¤í–‰
echo "ğŸ”„ Starting backup at $(date)"
pg_dump -h localhost -U backup_user -d recipt_production \
    --verbose --clean --no-owner --no-privileges \
    --exclude-table=audit_trails \
    --exclude-table=session_data \
    > "${BACKUP_DIR}/${BACKUP_FILE}"

# ì••ì¶•
gzip "${BACKUP_DIR}/${BACKUP_FILE}"

# ë°±ì—… ê²€ì¦
if [ -f "${BACKUP_DIR}/${BACKUP_FILE}.gz" ]; then
    SIZE=$(du -h "${BACKUP_DIR}/${BACKUP_FILE}.gz" | cut -f1)
    echo "âœ… Backup completed: ${BACKUP_FILE}.gz (${SIZE})"
    
    # Slack ì•Œë¦¼ (ì„ íƒì )
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"âœ… Database backup completed: ${SIZE}\"}" \
        https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK
else
    echo "âŒ Backup failed"
    exit 1
fi

# ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬ (30ì¼ ì´ì „)
find $BACKUP_DIR -name "recipt_backup_*.sql.gz" -mtime +30 -delete

echo "ğŸ‰ Backup process completed at $(date)"
```

### 7.2 ë³µêµ¬ ì‹¤íŒ¨

#### ì¦ìƒ
```
psql: error: connection to server failed: FATAL: database "recipt_production" does not exist
```

#### í•´ê²° ë°©ë²•

**Step 1: ë°ì´í„°ë² ì´ìŠ¤ ì¬ìƒì„±**
```sql
-- ìŠˆí¼ìœ ì €ë¡œ ì—°ê²°
sudo -u postgres psql

-- ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
CREATE DATABASE recipt_production
WITH OWNER = recipt_prod
     ENCODING = 'UTF8'
     LC_COLLATE = 'ko_KR.UTF-8'
     LC_CTYPE = 'ko_KR.UTF-8';

-- í•„ìˆ˜ í™•ì¥ ì„¤ì¹˜
\c recipt_production
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pgcrypto";
CREATE EXTENSION IF NOT EXISTS "pg_trgm";
```

**Step 2: ë³µêµ¬ ì‹¤í–‰**
```bash
# ë°±ì—… íŒŒì¼ ì••ì¶• í•´ì œ
gunzip recipt_backup_20250111_143000.sql.gz

# ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬
psql -h localhost -U recipt_prod -d recipt_production \
    < recipt_backup_20250111_143000.sql

# ë³µêµ¬ ê²€ì¦
psql -h localhost -U recipt_prod -d recipt_production -c "
SELECT 
    schemaname,
    COUNT(*) as table_count
FROM pg_tables 
WHERE schemaname = 'public'
GROUP BY schemaname;
"
```

---

## 8. ëª¨ë‹ˆí„°ë§ ë° ì§„ë‹¨ ë„êµ¬

### 8.1 ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¿¼ë¦¬

```sql
-- ë°ì´í„°ë² ì´ìŠ¤ ì „ì²´ í†µê³„
SELECT 
    datname,
    numbackends as connections,
    xact_commit,
    xact_rollback,
    blks_read,
    blks_hit,
    round(100.0 * blks_hit / NULLIF(blks_hit + blks_read, 0), 2) as cache_hit_ratio
FROM pg_stat_database
WHERE datname = 'recipt_production';

-- í…Œì´ë¸”ë³„ ì‚¬ìš©ëŸ‰
SELECT 
    schemaname,
    tablename,
    n_tup_ins as inserts,
    n_tup_upd as updates,
    n_tup_del as deletes,
    n_live_tup as live_tuples,
    n_dead_tup as dead_tuples,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_stat_user_tables
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- ì¸ë±ìŠ¤ íš¨ìœ¨ì„±
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_tup_read,
    idx_tup_fetch,
    CASE WHEN idx_tup_read > 0 
         THEN round(100.0 * idx_tup_fetch / idx_tup_read, 2)
         ELSE 0 
    END as selectivity
FROM pg_stat_user_indexes
ORDER BY idx_tup_read DESC;
```

### 8.2 ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬

```bash
#!/bin/bash
# health-check.sh

echo "=== Database Health Check $(date) ==="

# 1. ì„œë¹„ìŠ¤ ìƒíƒœ
echo "ğŸ“Š Service Status:"
systemctl is-active postgresql || echo "âŒ PostgreSQL not running"

# 2. ì—°ê²° í…ŒìŠ¤íŠ¸
echo "ğŸ”— Connection Test:"
timeout 5 psql -h localhost -U recipt_prod -d recipt_production -c "SELECT 1;" > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ… Database connection OK"
else
    echo "âŒ Database connection failed"
fi

# 3. ë””ìŠ¤í¬ ê³µê°„
echo "ğŸ’¾ Disk Space:"
df -h /var/lib/postgresql | tail -1 | awk '{
    if ($5+0 > 90) 
        print "âŒ Disk usage critical: " $5
    else if ($5+0 > 80)
        print "âš ï¸  Disk usage high: " $5
    else
        print "âœ… Disk usage OK: " $5
}'

# 4. í™œì„± ì—°ê²° ìˆ˜
echo "ğŸ”Œ Active Connections:"
CONNECTIONS=$(psql -h localhost -U recipt_prod -d recipt_production -t -c "SELECT count(*) FROM pg_stat_activity;")
if [ $CONNECTIONS -gt 80 ]; then
    echo "âŒ Too many connections: $CONNECTIONS"
elif [ $CONNECTIONS -gt 50 ]; then
    echo "âš ï¸  High connection count: $CONNECTIONS"
else
    echo "âœ… Connection count OK: $CONNECTIONS"
fi

# 5. ëŠë¦° ì¿¼ë¦¬
echo "ğŸŒ Slow Queries:"
SLOW_QUERIES=$(psql -h localhost -U recipt_prod -d recipt_production -t -c "
SELECT count(*) 
FROM pg_stat_activity 
WHERE state = 'active' 
    AND now() - query_start > interval '30 seconds';
")
if [ $SLOW_QUERIES -gt 0 ]; then
    echo "âš ï¸  Slow queries detected: $SLOW_QUERIES"
else
    echo "âœ… No slow queries"
fi

echo "=== Health Check Completed ==="
```

### 8.3 ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ ìƒì„±

```sql
-- ì‹¤ì‹œê°„ ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ ì¿¼ë¦¬
WITH database_stats AS (
    SELECT 
        datname,
        round(100.0 * blks_hit / NULLIF(blks_hit + blks_read, 0), 2) as cache_hit_ratio,
        xact_commit,
        xact_rollback
    FROM pg_stat_database
    WHERE datname = 'recipt_production'
),
connection_stats AS (
    SELECT 
        count(*) as total_connections,
        count(*) FILTER (WHERE state = 'active') as active_connections,
        count(*) FILTER (WHERE state = 'idle') as idle_connections
    FROM pg_stat_activity
),
table_stats AS (
    SELECT 
        sum(n_tup_ins) as total_inserts,
        sum(n_tup_upd) as total_updates,
        sum(n_tup_del) as total_deletes
    FROM pg_stat_user_tables
)
SELECT 
    'Database Performance Dashboard' as title,
    d.cache_hit_ratio,
    c.total_connections,
    c.active_connections,
    c.idle_connections,
    t.total_inserts,
    t.total_updates,
    t.total_deletes,
    d.xact_commit,
    d.xact_rollback
FROM database_stats d, connection_stats c, table_stats t;
```

---

## 9. ì‘ê¸‰ ìƒí™© ëŒ€ì‘

### 9.1 ì„œë¹„ìŠ¤ ì¤‘ë‹¨ ëŒ€ì‘

#### ë‹¨ê³„ë³„ ëŒ€ì‘ ì ˆì°¨

**1ë‹¨ê³„: ì¦‰ì‹œ ëŒ€ì‘ (5ë¶„ ì´ë‚´)**
1. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
2. ì—ëŸ¬ ë¡œê·¸ ìˆ˜ì§‘
3. ê¸°ìˆ íŒ€ ê¸´ê¸‰ ì—°ë½
4. ì‚¬ìš©ì ê³µì§€ ì¤€ë¹„

```bash
# ì‘ê¸‰ ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸
#!/bin/bash
# emergency-diagnosis.sh

echo "ğŸš¨ EMERGENCY DIAGNOSIS STARTED $(date)"

# PostgreSQL ìƒíƒœ
echo "1. PostgreSQL Status:"
systemctl status postgresql --no-pager

# ì—°ê²° í…ŒìŠ¤íŠ¸
echo "2. Connection Test:"
timeout 3 psql -h localhost -U recipt_prod -d recipt_production -c "SELECT 1;"

# ë””ìŠ¤í¬ ê³µê°„
echo "3. Disk Space:"
df -h | grep -E '(Filesystem|/var/lib/postgresql|/)'

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
echo "4. Memory Usage:"
free -h

# í™œì„± ì—°ê²°
echo "5. Active Connections:"
psql -h localhost -U recipt_prod -d recipt_production -c "
SELECT count(*), state 
FROM pg_stat_activity 
GROUP BY state;
" 2>/dev/null || echo "Connection failed"

# ìµœê·¼ ì—ëŸ¬ ë¡œê·¸
echo "6. Recent Errors:"
tail -20 /var/log/postgresql/postgresql-*.log | grep ERROR

echo "ğŸš¨ EMERGENCY DIAGNOSIS COMPLETED $(date)"
```

**2ë‹¨ê³„: ìƒí™© ë¶„ì„ (15ë¶„ ì´ë‚´)**
```bash
# ìƒì„¸ ë¶„ì„
echo "ğŸ“Š DETAILED ANALYSIS:"

# ì˜¤ë˜ ì‹¤í–‰ë˜ëŠ” ì¿¼ë¦¬
psql -h localhost -U recipt_prod -d recipt_production -c "
SELECT pid, now() - pg_stat_activity.query_start AS duration, query, state
FROM pg_stat_activity
WHERE (now() - pg_stat_activity.query_start) > interval '1 minutes'
ORDER BY duration DESC;
"

# ë½ ìƒí™©
psql -h localhost -U recipt_prod -d recipt_production -c "
SELECT 
    l.mode,
    l.locktype,
    l.pid,
    a.query,
    a.state
FROM pg_locks l
JOIN pg_stat_activity a ON l.pid = a.pid
WHERE NOT l.granted;
"

# ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
echo "System Load: $(uptime)"
echo "Top processes:"
ps aux --sort=-%cpu | head -10
```

**3ë‹¨ê³„: ë³µêµ¬ ì‹œë„ (30ë¶„ ì´ë‚´)**

```bash
# ë³µêµ¬ ì‹œë„ ìŠ¤í¬ë¦½íŠ¸
#!/bin/bash
# emergency-recovery.sh

echo "ğŸ”§ EMERGENCY RECOVERY STARTED $(date)"

# 1. ì„œë¹„ìŠ¤ ì¬ì‹œì‘ ì‹œë„
echo "Restarting PostgreSQL service..."
sudo systemctl restart postgresql

sleep 10

# 2. ì—°ê²° í…ŒìŠ¤íŠ¸
if timeout 5 psql -h localhost -U recipt_prod -d recipt_production -c "SELECT 1;" > /dev/null 2>&1; then
    echo "âœ… PostgreSQL restarted successfully"
else
    echo "âŒ PostgreSQL restart failed"
    
    # 3. ì‘ê¸‰ ë³µêµ¬ ì‹œë„
    echo "Attempting emergency recovery..."
    
    # ë°±ì—…ì—ì„œ ë³µêµ¬
    LATEST_BACKUP=$(ls -t /backup/database/recipt_backup_*.sql.gz | head -1)
    if [ -n "$LATEST_BACKUP" ]; then
        echo "Found backup: $LATEST_BACKUP"
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì¬ìƒì„±
        sudo -u postgres psql -c "DROP DATABASE IF EXISTS recipt_production;"
        sudo -u postgres psql -c "CREATE DATABASE recipt_production WITH OWNER recipt_prod;"
        
        # ë°±ì—… ë³µêµ¬
        gunzip -c $LATEST_BACKUP | psql -h localhost -U recipt_prod -d recipt_production
        
        echo "âœ… Recovery from backup completed"
    else
        echo "âŒ No backup found for recovery"
    fi
fi

# 4. ìƒíƒœ í™•ì¸
./health-check.sh

echo "ğŸ”§ EMERGENCY RECOVERY COMPLETED $(date)"
```

### 9.2 ì—ìŠ¤ì»¬ë ˆì´ì…˜ ì ˆì°¨

#### ì—°ë½ë§ ë° ì—­í• 

**Tier 1 - ìš´ì˜íŒ€ (24/7)**
- ì´ˆê¸° ëŒ€ì‘ ë° ìƒí™© íŒŒì•…
- ê¸°ë³¸ ì§„ë‹¨ ë° ë¡œê·¸ ìˆ˜ì§‘
- ì„œë¹„ìŠ¤ ì¬ì‹œì‘ ë“± ê¸°ë³¸ ë³µêµ¬ ì‹œë„

**Tier 2 - ê¸°ìˆ íŒ€ (í‰ì¼ 9-18ì‹œ, ì£¼ë§ ì˜¨ì½œ)**
- ìƒì„¸ ê¸°ìˆ  ë¶„ì„
- ë³µì¡í•œ ë³µêµ¬ ì‘ì—…
- ì„ì‹œ í•´ê²°ì±… êµ¬í˜„

**Tier 3 - ì „ë¬¸ê°€ (ì˜¨ë””ë§¨ë“œ)**
- í•µì‹¬ ì‹œìŠ¤í…œ ì„¤ê³„ì
- ì™¸ë¶€ ì „ë¬¸ê°€
- ë²¤ë” ê¸°ìˆ  ì§€ì›

#### ì—ìŠ¤ì»¬ë ˆì´ì…˜ ê¸°ì¤€

| ì‹œê°„ | ìƒí™© | ì—ìŠ¤ì»¬ë ˆì´ì…˜ |
|------|------|-------------|
| ì¦‰ì‹œ | ì „ì²´ ì„œë¹„ìŠ¤ ì¤‘ë‹¨ | Tier 1 â†’ Tier 2 |
| 15ë¶„ | ê¸°ë³¸ ë³µêµ¬ ì‹¤íŒ¨ | Tier 2 â†’ Tier 3 |
| 30ë¶„ | ë°ì´í„° ì†ì‹¤ ìœ„í—˜ | ëª¨ë“  Tier ë™ì› |
| 1ì‹œê°„ | ë³µêµ¬ ë¶ˆê°€ | ê²½ì˜ì§„ ë³´ê³  |

### 9.3 ì‚¬í›„ ë¶„ì„ ë° ê°œì„ 

#### ì‚¬í›„ ë¶„ì„ í…œí”Œë¦¿

```markdown
# ì¥ì•  ì‚¬í›„ ë¶„ì„ ë³´ê³ ì„œ

## ì¥ì•  ê°œìš”
- **ë°œìƒì¼ì‹œ**: 2025-01-11 14:30:00 ~ 15:15:00 (45ë¶„)
- **ì˜í–¥ ë²”ìœ„**: ì „ì²´ ì‚¬ìš©ì
- **ì¥ì•  ì‹¬ê°ë„**: Critical
- **ìµœì´ˆ ê°ì§€**: ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì•Œë¦¼

## íƒ€ì„ë¼ì¸
| ì‹œê°„ | ì´ë²¤íŠ¸ | ëŒ€ì‘ì | ì¡°ì¹˜ |
|------|-------|--------|------|
| 14:30 | ì„œë¹„ìŠ¤ ì‘ë‹µ ì—†ìŒ ê°ì§€ | ëª¨ë‹ˆí„°ë§ | ìë™ ì•Œë¦¼ |
| 14:32 | ê¸°ìˆ íŒ€ ìƒí™© í™•ì¸ | ê°œë°œíŒ€ | ë¡œê·¸ í™•ì¸ |
| 14:35 | DB ì—°ê²° ë¶ˆê°€ í™•ì¸ | DevOps | ì„œë¹„ìŠ¤ ì¬ì‹œì‘ |
| 14:50 | ë°±ì—…ìœ¼ë¡œ ë³µêµ¬ ê²°ì • | ê¸°ìˆ íŒ€ì¥ | ë°±ì—… ë³µêµ¬ |
| 15:15 | ì„œë¹„ìŠ¤ ì •ìƒí™” | ì „ì²´íŒ€ | ìƒíƒœ ëª¨ë‹ˆí„°ë§ |

## ê·¼ë³¸ ì›ì¸
- **ì§ì ‘ ì›ì¸**: PostgreSQL í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì¢…ë£Œ
- **ê·¼ë³¸ ì›ì¸**: ëŠë¦° ì¿¼ë¦¬ ëˆ„ì ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸‰ì¦
- **ê¸°ì—¬ ìš”ì¸**: ì¸ë±ìŠ¤ ëˆ„ë½, ë¹„íš¨ìœ¨ì  ì¿¼ë¦¬

## ì˜í–¥ ë¶„ì„
- **ì‚¬ìš©ì**: 45ë¶„ê°„ ì„œë¹„ìŠ¤ ì ‘ê·¼ ë¶ˆê°€
- **ë°ì´í„°**: ìµœê·¼ 30ë¶„ ë°ì´í„° ì†ì‹¤ (ë°±ì—… ì‹œì  ì°¨ì´)
- **ë¹„ì¦ˆë‹ˆìŠ¤**: ì˜ˆì‚° ìŠ¹ì¸ ì—…ë¬´ ì§€ì—°

## ê°œì„  ê³„íš
1. **ì¦‰ì‹œ ì¡°ì¹˜** (1ì£¼ì¼)
   - ë¬¸ì œ ì¿¼ë¦¬ì— ì¸ë±ìŠ¤ ì¶”ê°€
   - ë©”ëª¨ë¦¬ ì„¤ì • ìµœì í™”
   - ëª¨ë‹ˆí„°ë§ ì„ê³„ê°’ ì¡°ì •

2. **ë‹¨ê¸° ê°œì„ ** (1ê°œì›”)
   - ì¿¼ë¦¬ ì„±ëŠ¥ ìë™ ë¶„ì„ ë„êµ¬ ë„ì…
   - ë°±ì—… ì£¼ê¸° ë‹¨ì¶• (4ì‹œê°„ â†’ 1ì‹œê°„)
   - ì¥ì•  ëŒ€ì‘ ë§¤ë‰´ì–¼ ì—…ë°ì´íŠ¸

3. **ì¥ê¸° ê°œì„ ** (3ê°œì›”)
   - ê³ ê°€ìš©ì„± êµ¬ì„± (ë³µì œ ì„œë²„ êµ¬ì¶•)
   - ìë™ í˜ì¼ì˜¤ë²„ ì‹œìŠ¤í…œ êµ¬ì¶•
   - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•

## ì˜ˆë°©ì±…
- ì •ê¸°ì ì¸ ì„±ëŠ¥ ë¦¬ë·° (ì›” 1íšŒ)
- ì¿¼ë¦¬ ì„±ëŠ¥ ê¸°ì¤€ ìˆ˜ë¦½
- ìš©ëŸ‰ ê³„íš í”„ë¡œì„¸ìŠ¤ ì •ë¹„

## í•™ìŠµ ì‚¬í•­
- ì‚¬ì „ ëª¨ë‹ˆí„°ë§ì˜ ì¤‘ìš”ì„± ì¬í™•ì¸
- ë°±ì—…/ë³µêµ¬ ì ˆì°¨ ê°œì„  í•„ìš”
- íŒ€ ê°„ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í”„ë¡œì„¸ìŠ¤ ê°œì„ 
```

---

## 10. ì¶”ê°€ ë¦¬ì†ŒìŠ¤ ë° ì°¸ê³  ìë£Œ

### 10.1 ìœ ìš©í•œ ëª…ë ¹ì–´ ëª¨ìŒ

```bash
# PostgreSQL ê´€ë ¨
sudo systemctl status postgresql          # ì„œë¹„ìŠ¤ ìƒíƒœ
sudo systemctl restart postgresql         # ì„œë¹„ìŠ¤ ì¬ì‹œì‘
sudo -u postgres psql                     # ìŠˆí¼ìœ ì €ë¡œ ì ‘ì†
pg_isready -h localhost -p 5432          # ì—°ê²° ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸

# ë¡œê·¸ ê´€ë ¨
tail -f /var/log/postgresql/postgresql-*.log    # ì‹¤ì‹œê°„ ë¡œê·¸
journalctl -u postgresql -f                     # systemd ë¡œê·¸
grep ERROR /var/log/postgresql/postgresql-*.log # ì—ëŸ¬ ë¡œê·¸ë§Œ

# ë°±ì—…/ë³µêµ¬
pg_dump -h localhost -U user db > backup.sql    # ë°±ì—…
psql -h localhost -U user db < backup.sql       # ë³µêµ¬
pg_basebackup -D /backup/base -Ft -z -P         # ë¬¼ë¦¬ì  ë°±ì—…

# ì„±ëŠ¥ ë¶„ì„
pgbench -c 10 -T 60 recipt_production           # ë²¤ì¹˜ë§ˆí¬
explain analyze SELECT * FROM users LIMIT 10;    # ì¿¼ë¦¬ ë¶„ì„
```

### 10.2 ëª¨ë‹ˆí„°ë§ ë„êµ¬

#### Prometheus + Grafana ì„¤ì • ì˜ˆì‹œ
```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'postgres'
    static_configs:
      - targets: ['localhost:9187']
    scrape_interval: 30s
```

#### í•µì‹¬ ë©”íŠ¸ë¦­
- **ì—°ê²° ìˆ˜**: active_connections, idle_connections
- **ì¿¼ë¦¬ ì„±ëŠ¥**: avg_query_time, slow_query_count
- **ë¦¬ì†ŒìŠ¤**: cpu_usage, memory_usage, disk_io
- **ì—ëŸ¬ìœ¨**: connection_errors, query_errors

### 10.3 ê´€ë ¨ ë¬¸ì„œ
- [ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì¢…í•© ë¬¸ì„œ](./schema-documentation.md)
- [ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ ê°€ì´ë“œ](./migration-guide.md)
- [API ë°ì´í„° ëª¨ë¸](./api-data-models.md)

### 10.4 ì™¸ë¶€ ì°¸ì¡°
- [PostgreSQL ê³µì‹ ë¬¸ì„œ](https://www.postgresql.org/docs/)
- [TypeORM íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](https://typeorm.io/troubleshooting)
- [PostgreSQL Wiki](https://wiki.postgresql.org/)
- [PostgreSQL ì„±ëŠ¥ íŠœë‹ ê°€ì´ë“œ](https://wiki.postgresql.org/wiki/Performance_Optimization)

---

**ê¸´ê¸‰ ì—°ë½ì²˜**
- **ê¸°ìˆ íŒ€ì¥**: 010-0000-0000
- **DB ê´€ë¦¬ì**: 010-0000-0001  
- **DevOps ë‹´ë‹¹**: 010-0000-0002
- **ë¹„ìƒ Slack**: #db-emergency

**ë¬¸ì„œ ì •ë³´**
- **ë²„ì „**: 1.0
- **ì‘ì„±ì¼**: 2025-01-11
- **ì‘ì„±ì**: Backend Development Team
- **ê²€í† ì**: DevOps Team, Database Administrator
- **ìŠ¹ì¸ì**: Technical Lead
- **ë‹¤ìŒ ê²€í†  ì˜ˆì •ì¼**: 2025-02-11

---

> âš ï¸ **ì£¼ì˜ì‚¬í•­**: ì´ ë¬¸ì„œì˜ ëª¨ë“  ëª…ë ¹ì–´ëŠ” í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ ë¨¼ì € ê²€ì¦í•œ í›„ í”„ë¡œë•ì…˜ì— ì ìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

> ğŸ†˜ **ì‘ê¸‰ ìƒí™©**: ë¬¸ì œ í•´ê²°ì´ ì–´ë ¤ìš´ ê²½ìš° ì¦‰ì‹œ ê¸°ìˆ íŒ€ì— ì—°ë½í•˜ê³ , ì´ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì—¬ ìƒí™©ì„ ì„¤ëª…í•´ ì£¼ì„¸ìš”.